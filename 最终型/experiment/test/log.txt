HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
    (swinT): SwinT1(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
    (OCAB): SwinT2(
      (transformer_body): Sequential(
        (0): BasicLayer2(
          (blocks): ModuleList(
            (0): OCAB(
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (unfold): Unfold(kernel_size=(12, 12), dilation=1, padding=2, stride=8)
              (softmax): Softmax(dim=-1)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=96, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=96, out_features=192, bias=True)
                (fc3): Linear(in_features=192, out_features=96, bias=True)
                (fc4): Linear(in_features=96, out_features=48, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B2): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
    (swinT): SwinT1(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
    (OCAB): SwinT2(
      (transformer_body): Sequential(
        (0): BasicLayer2(
          (blocks): ModuleList(
            (0): OCAB(
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (unfold): Unfold(kernel_size=(12, 12), dilation=1, padding=2, stride=8)
              (softmax): Softmax(dim=-1)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=96, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=96, out_features=192, bias=True)
                (fc3): Linear(in_features=192, out_features=96, bias=True)
                (fc4): Linear(in_features=96, out_features=48, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B3): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
    (swinT): SwinT1(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
    (OCAB): SwinT2(
      (transformer_body): Sequential(
        (0): BasicLayer2(
          (blocks): ModuleList(
            (0): OCAB(
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (unfold): Unfold(kernel_size=(12, 12), dilation=1, padding=2, stride=8)
              (softmax): Softmax(dim=-1)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=96, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=96, out_features=192, bias=True)
                (fc3): Linear(in_features=192, out_features=96, bias=True)
                (fc4): Linear(in_features=96, out_features=48, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B4): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
    (swinT): SwinT1(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(1, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
    (OCAB): SwinT2(
      (transformer_body): Sequential(
        (0): BasicLayer2(
          (blocks): ModuleList(
            (0): OCAB(
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (unfold): Unfold(kernel_size=(12, 12), dilation=1, padding=2, stride=8)
              (softmax): Softmax(dim=-1)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=96, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=96, out_features=192, bias=True)
                (fc3): Linear(in_features=192, out_features=96, bias=True)
                (fc4): Linear(in_features=96, out_features=48, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 6.34s

Saving...
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 5.58s

Saving...
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 5.66s

Saving...
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 6.05s

Saving...
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 5.66s

Saving...
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 5.66s

Saving...
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 5.68s

Saving...
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 5.55s

Saving...
Total: 5.57s


Evaluation:
[Set5 x4]	PSNR: 8.844 (Best: 8.844 @epoch 1)
Forward: 5.40s

Saving...
Total: 5.42s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	15.3+19.6s
[200/800]	[L1: 0.0873]	15.0+1.5s
[300/800]	[L1: 0.0768]	14.9+1.7s
[400/800]	[L1: 0.0692]	14.9+1.7s
[500/800]	[L1: 0.0640]	15.1+1.6s
[600/800]	[L1: 0.0603]	15.1+1.6s
[700/800]	[L1: 0.0576]	15.3+1.5s
[800/800]	[L1: 0.0555]	15.1+1.6s

Evaluation:
[Set5 x4]	PSNR: 27.892 (Best: 27.892 @epoch 1)
Forward: 6.88s

Saving...
Total: 6.96s

[Epoch 1]	Learning rate: 5.00e-4
[100/800]	[L1: 0.0425]	15.3+19.7s
[200/800]	[L1: 0.0427]	15.0+1.5s
[300/800]	[L1: 0.0414]	15.0+1.6s
[400/800]	[L1: 0.0403]	15.1+1.6s
[500/800]	[L1: 0.0402]	15.1+1.6s
[600/800]	[L1: 0.0399]	15.0+1.6s
[700/800]	[L1: 0.0392]	15.2+1.6s
[800/800]	[L1: 0.0386]	15.1+1.6s

Evaluation:
[Set5 x4]	PSNR: 28.581 (Best: 28.581 @epoch 2)
Forward: 6.38s

Saving...
Total: 6.45s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	16.4+20.7s
[200/800]	[L1: 0.0873]	15.2+1.5s
[300/800]	[L1: 0.0770]	15.3+1.5s
[400/800]	[L1: 0.0692]	15.4+1.5s
[500/800]	[L1: 0.0639]	15.3+1.5s
[600/800]	[L1: 0.0602]	15.5+1.4s
[700/800]	[L1: 0.0577]	15.4+1.4s
[800/800]	[L1: 0.0558]	15.3+1.5s

Evaluation:
[Set5 x4]	PSNR: 27.440 (Best: 27.440 @epoch 1)
Forward: 7.42s

Saving...
Total: 7.48s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1105]	24.7+20.6s
[200/800]	[L1: 0.0870]	23.6+2.4s
[300/800]	[L1: 0.0767]	23.6+2.5s
[400/800]	[L1: 0.0688]	23.6+2.4s
[500/800]	[L1: 0.0639]	23.6+2.4s
[600/800]	[L1: 0.0602]	23.6+2.5s
[700/800]	[L1: 0.0575]	23.6+2.4s
[800/800]	[L1: 0.0554]	23.6+2.4s

Evaluation:
[Set5 x4]	PSNR: 27.901 (Best: 27.901 @epoch 1)
Forward: 6.86s

Saving...
Total: 6.94s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	24.1+20.5s
[200/800]	[L1: 0.0875]	23.2+2.4s
[300/800]	[L1: 0.0772]	23.5+2.5s
[400/800]	[L1: 0.0694]	23.6+2.5s
[500/800]	[L1: 0.0639]	23.6+2.4s
[600/800]	[L1: 0.0599]	23.6+2.5s
[700/800]	[L1: 0.0573]	23.5+2.5s
[800/800]	[L1: 0.0553]	23.5+2.5s

Evaluation:
[Set5 x4]	PSNR: 27.501 (Best: 27.501 @epoch 1)
Forward: 6.99s

Saving...
Total: 7.08s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1103]	15.8+19.4s
[200/800]	[L1: 0.0875]	15.1+1.5s
[300/800]	[L1: 0.0771]	15.4+1.4s
[400/800]	[L1: 0.0690]	15.3+1.5s
[500/800]	[L1: 0.0639]	15.4+1.4s
[600/800]	[L1: 0.0601]	15.6+1.3s
[700/800]	[L1: 0.0576]	15.5+1.4s
[800/800]	[L1: 0.0555]	15.6+1.3s

Evaluation:
[Set5 x4]	PSNR: 27.835 (Best: 27.835 @epoch 1)
Forward: 7.17s

Saving...
Total: 7.25s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	15.9+19.4s
[200/800]	[L1: 0.0872]	15.4+1.3s
[300/800]	[L1: 0.0768]	15.4+1.4s
[400/800]	[L1: 0.0687]	15.6+1.3s
[500/800]	[L1: 0.0637]	15.6+1.3s
[600/800]	[L1: 0.0602]	15.6+1.3s
[700/800]	[L1: 0.0575]	15.6+1.5s
[800/800]	[L1: 0.0555]	15.5+1.5s

Evaluation:
[Set5 x4]	PSNR: 27.840 (Best: 27.840 @epoch 1)
Forward: 8.53s

Saving...
Total: 8.61s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	24.3+20.9s
[200/800]	[L1: 0.0874]	23.7+2.5s
[300/800]	[L1: 0.0772]	23.6+2.5s
[400/800]	[L1: 0.0694]	23.6+2.5s
[500/800]	[L1: 0.0645]	23.6+2.5s
[600/800]	[L1: 0.0610]	23.6+2.5s
[700/800]	[L1: 0.0584]	23.6+2.5s
[800/800]	[L1: 0.0563]	23.6+2.4s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	24.0+20.4s
[200/800]	[L1: 0.0872]	23.4+2.7s
[300/800]	[L1: 0.0774]	23.6+2.5s
[400/800]	[L1: 0.0696]	23.3+2.7s
[500/800]	[L1: 0.0643]	23.6+2.4s
[600/800]	[L1: 0.0606]	23.4+2.6s
[700/800]	[L1: 0.0578]	23.6+2.5s
[800/800]	[L1: 0.0558]	23.5+2.5s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	24.2+22.2s
[200/800]	[L1: 0.0873]	23.4+2.7s
[300/800]	[L1: 0.0767]	23.5+2.6s
[400/800]	[L1: 0.0692]	23.5+2.5s
[500/800]	[L1: 0.0639]	23.5+2.6s
[600/800]	[L1: 0.0599]	23.5+2.7s
[700/800]	[L1: 0.0574]	23.4+2.8s
[800/800]	[L1: 0.0556]	23.5+2.7s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	24.0+21.0s
[200/800]	[L1: 0.0872]	23.3+2.8s
[300/800]	[L1: 0.0767]	23.4+2.7s
[400/800]	[L1: 0.0688]	23.3+2.8s
[500/800]	[L1: 0.0633]	23.4+2.7s
[600/800]	[L1: 0.0593]	23.2+2.9s
[700/800]	[L1: 0.0567]	23.4+2.7s
[800/800]	[L1: 0.0548]	23.5+2.6s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	16.2+20.6s
[200/800]	[L1: 0.0872]	15.4+1.4s
[300/800]	[L1: 0.0767]	15.4+1.5s
[400/800]	[L1: 0.0690]	15.6+1.5s
[500/800]	[L1: 0.0636]	15.4+1.5s
[600/800]	[L1: 0.0603]	15.3+1.5s
[700/800]	[L1: 0.0576]	15.1+1.6s
[800/800]	[L1: 0.0556]	15.3+1.5s

Evaluation:
[Set5 x4]	PSNR: 26.769 (Best: 26.769 @epoch 1)
Forward: 7.17s

Saving...
Total: 7.25s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	15.9+19.5s
[200/800]	[L1: 0.0871]	15.1+1.5s
[300/800]	[L1: 0.0768]	15.1+1.6s
[400/800]	[L1: 0.0691]	15.2+1.6s
[500/800]	[L1: 0.0638]	15.2+1.6s
[600/800]	[L1: 0.0603]	16.1+1.3s
[700/800]	[L1: 0.0576]	15.3+1.6s
[800/800]	[L1: 0.0555]	15.2+1.6s

Evaluation:
[Set5 x4]	PSNR: 27.186 (Best: 27.186 @epoch 1)
Forward: 7.38s

Saving...
Total: 7.47s

HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	15.8+19.7s
[200/800]	[L1: 0.0878]	15.1+1.5s
[300/800]	[L1: 0.0775]	15.2+1.5s
[400/800]	[L1: 0.0693]	15.2+1.6s
[500/800]	[L1: 0.0638]	15.3+1.6s
[600/800]	[L1: 0.0600]	15.2+1.6s
[700/800]	[L1: 0.0574]	15.3+1.6s
[800/800]	[L1: 0.0555]	15.3+1.5s

Evaluation:
HNCT(
  (fea_conv): Conv2d(4, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	15.9+19.6s
[200/800]	[L1: 0.0871]	15.2+1.5s
[300/800]	[L1: 0.0765]	15.3+1.6s
[400/800]	[L1: 0.0685]	15.3+1.6s
[500/800]	[L1: 0.0633]	15.4+1.5s
[600/800]	[L1: 0.0596]	15.3+1.6s
[700/800]	[L1: 0.0571]	15.3+1.6s
[800/800]	[L1: 0.0551]	15.3+1.6s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	15.7+19.8s
[200/800]	[L1: 0.0873]	15.0+1.6s
[300/800]	[L1: 0.0767]	15.1+1.6s
[400/800]	[L1: 0.0688]	15.2+1.6s
[500/800]	[L1: 0.0638]	15.2+1.6s
[600/800]	[L1: 0.0604]	15.2+1.6s
[700/800]	[L1: 0.0578]	15.2+1.6s
[800/800]	[L1: 0.0558]	15.1+1.7s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	15.8+19.7s
[200/800]	[L1: 0.0873]	15.2+1.6s
[300/800]	[L1: 0.0768]	15.3+1.6s
[400/800]	[L1: 0.0692]	15.2+1.7s
[500/800]	[L1: 0.0642]	15.2+1.7s
[600/800]	[L1: 0.0603]	15.1+1.7s
[700/800]	[L1: 0.0576]	15.1+1.7s
[800/800]	[L1: 0.0555]	15.1+1.7s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	24.0+20.9s
[200/800]	[L1: 0.0872]	23.4+2.7s
[300/800]	[L1: 0.0766]	23.4+2.7s
[400/800]	[L1: 0.0689]	23.4+2.7s
[500/800]	[L1: 0.0636]	23.4+2.7s
[600/800]	[L1: 0.0598]	23.4+2.7s
[700/800]	[L1: 0.0573]	23.4+2.7s
[800/800]	[L1: 0.0553]	23.4+2.7s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	24.0+21.6s
[200/800]	[L1: 0.0874]	23.4+2.7s
[300/800]	[L1: 0.0771]	23.4+2.7s
[400/800]	[L1: 0.0693]	23.4+2.7s
[500/800]	[L1: 0.0640]	23.3+2.8s
[600/800]	[L1: 0.0601]	23.4+2.7s
[700/800]	[L1: 0.0576]	23.4+2.7s
[800/800]	[L1: 0.0557]	23.4+2.7s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1125]	24.1+20.4s
[200/800]	[L1: 0.0854]	23.6+2.5s
[300/800]	[L1: 0.0748]	23.6+2.5s
[400/800]	[L1: 0.0677]	23.6+2.5s
[500/800]	[L1: 0.0635]	23.7+2.4s
[600/800]	[L1: 0.0600]	23.6+2.5s
[700/800]	[L1: 0.0579]	23.6+2.5s
[800/800]	[L1: 0.0557]	23.6+2.5s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	16.7+22.5s
[200/800]	[L1: 0.0874]	15.9+1.4s
[300/800]	[L1: 0.0768]	15.6+1.5s
[400/800]	[L1: 0.0688]	15.8+1.5s
[500/800]	[L1: 0.0636]	15.8+1.5s
[600/800]	[L1: 0.0599]	16.2+1.4s
[700/800]	[L1: 0.0573]	16.0+1.4s
[800/800]	[L1: 0.0552]	15.7+1.5s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	16.3+21.7s
[200/800]	[L1: 0.0872]	16.1+1.3s
[300/800]	[L1: 0.0765]	15.9+1.5s
[400/800]	[L1: 0.0687]	16.2+1.3s
[500/800]	[L1: 0.0635]	16.0+1.4s
[600/800]	[L1: 0.0597]	16.0+1.4s
[700/800]	[L1: 0.0572]	16.5+1.2s
[800/800]	[L1: 0.0552]	17.3+0.9s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1105]	21.8+21.9s
[200/800]	[L1: 0.0871]	32.6+4.8s
[300/800]	[L1: 0.0766]	32.7+4.9s
[400/800]	[L1: 0.0690]	32.7+4.9s
[500/800]	[L1: 0.0640]	23.5+2.7s
[600/800]	[L1: 0.0602]	15.6+1.5s
[700/800]	[L1: 0.0575]	15.8+1.4s
[800/800]	[L1: 0.0554]	15.5+1.5s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (ACA): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0-1): 2 x Adaptive_Channel_Attention(
              (qkv): Linear(in_features=48, out_features=144, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=48, out_features=48, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (ca): ChannelAttention(
                (attention): Sequential(
                  (0): AdaptiveAvgPool2d(output_size=1)
                  (1): Conv2d(48, 4, kernel_size=(1, 1), stride=(1, 1))
                  (2): ReLU(inplace=True)
                  (3): Conv2d(4, 48, kernel_size=(1, 1), stride=(1, 1))
                  (4): Sigmoid()
                )
              )
              (sa): Spartial_Attention(
                (_Spartial_Attention__layer): Sequential(
                  (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
                  (1): Sigmoid()
                )
              )
              (dwconv): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
              (channel_interaction): Sequential(
                (0): AdaptiveAvgPool2d(output_size=1)
                (1): Conv2d(48, 6, kernel_size=(1, 1), stride=(1, 1))
                (2): GELU(approximate='none')
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (spatial_interaction): Sequential(
                (0): Conv2d(48, 3, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
                (3): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))
              )
              (mlp): Mlp(
                (fc1): Linear(in_features=48, out_features=192, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=192, out_features=384, bias=True)
                (fc3): Linear(in_features=384, out_features=192, bias=True)
                (fc4): Linear(in_features=192, out_features=48, bias=True)
              )
              (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (SAM): SAM(
    (basic_block): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_2): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (basic_block_4): DB(
      (conv_layers): ModuleList(
        (0): conv_relu(
          (conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
        (1): conv_relu(
          (conv): Sequential(
            (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (2): conv_relu(
          (conv): Sequential(
            (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
            (1): ReLU(inplace=True)
          )
        )
        (3): conv_relu(
          (conv): Sequential(
            (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
            (1): ReLU(inplace=True)
          )
        )
        (4): conv_relu(
          (conv): Sequential(
            (0): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU(inplace=True)
          )
        )
      )
      (conv_post): conv(
        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fusion): CSAF(
      (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))
      (compress1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
      (compress2): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1))
      (excitation): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (conv): ConvWithActivation(
    (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU()
  )
  (c): Sequential(
    (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[100/800]	[L1: 0.1104]	15.6+19.9s
[200/800]	[L1: 0.0872]	15.1+1.6s
[300/800]	[L1: 0.0766]	15.4+1.5s
[400/800]	[L1: 0.0689]	15.5+1.5s
[500/800]	[L1: 0.0638]	15.5+1.5s
[600/800]	[L1: 0.0601]	15.8+1.5s
[700/800]	[L1: 0.0575]	15.4+1.6s
[800/800]	[L1: 0.0554]	16.0+1.4s

Evaluation:
[Set14 x4]	PSNR: 25.697 (Best: 25.697 @epoch 1)
Forward: 11.98s

Saving...
Total: 12.08s

[Epoch 1]	Learning rate: 5.00e-4
[100/800]	[L1: 0.0417]	15.5+20.8s
[200/800]	[L1: 0.0423]	15.3+1.6s
[300/800]	[L1: 0.0412]	15.3+1.6s
[400/800]	[L1: 0.0399]	15.3+1.6s
[500/800]	[L1: 0.0395]	15.4+1.6s
[600/800]	[L1: 0.0391]	15.5+1.6s
[700/800]	[L1: 0.0388]	15.4+1.6s
[800/800]	[L1: 0.0385]	15.6+1.5s

Evaluation:
[Set14 x4]	PSNR: 26.152 (Best: 26.152 @epoch 2)
Forward: 10.81s

Saving...
Total: 10.90s

